{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occasional-bumper",
   "metadata": {},
   "source": [
    "# Train a binary classifier to classify income as below 50k or above 50k from census data\n",
    "\n",
    "## Dataset Information:\n",
    "\n",
    "The dataset is obtained from [Adult Data Set](https://archive.ics.uci.edu/ml/datasets/Adult). It consists of many multivariate features including demographics and income information. The task is to predict, if the income of a person is above or below $50k. \n",
    "\n",
    "### Setup\n",
    "\n",
    "To get started, make sure you have these prerequisites completed.\n",
    "\n",
    "* Specify an AWS Region to host your model.\n",
    "* An IAM role ARN exists that is used to give Amazon SageMaker access to your data in Amazon Simple Storage Service (Amazon S3). See the documentation for how to fine tune the permissions needed.\n",
    "* Create an S3 bucket used to store the data used to train your model, any additional model data, and the data captured from model invocations. For demonstration purposes, you are using the same bucket for these. In reality, you might want to separate them with different security policies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deluxe-merit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-us-west-2-179065836194\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-cannon",
   "metadata": {},
   "source": [
    "## Pre-process\n",
    "\n",
    "Create a Scikit-learn pipeline to handle pre-processing. It consists of following steps:\n",
    "* Create train-test split\n",
    "* Use simple imputer to substitute most frequent for categorical and mean for numerical features.\n",
    "* Use one-hot encoding for handling categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.csv')\n",
    "df.replace('?',np.NaN,inplace=True)\n",
    "\n",
    "df_train_val, df_test, = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train_val_no_target = df_train_val.drop('income', axis=1)\n",
    "\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anonymous-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x != object]\n",
    "cat_ind = [i for i, x in enumerate(df_train_val_no_target.dtypes) if x == object]\n",
    "\n",
    "numeric_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_ind),\n",
    "    ('cat', categorical_transformer, cat_ind)\n",
    "])\n",
    "\n",
    "X = preprocessor.fit_transform(df_train_val_no_target)\n",
    "\n",
    "y = LabelEncoder().fit_transform(df_train_val.income)\n",
    "X = np.insert(X, 0, y, axis=1)\n",
    "\n",
    "# Save the ColumnTransformer to be used during inference\n",
    "with open('script/preprocess.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-trouble",
   "metadata": {},
   "source": [
    "### Train-val split\n",
    "Split the training set again to create validation set and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rough-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "np.savetxt(\"data/train.csv\", X_train, delimiter=\",\", fmt='%f')\n",
    "np.savetxt(\"data/val.csv\", X_val, delimiter=\",\", fmt='%f')\n",
    "\n",
    "prefix = 'sagemaker/blog'\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv'))\\\n",
    ".upload_file('data/train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv'))\\\n",
    ".upload_file('data/val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-stewart",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "We train the model using SageMaker built-in XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baking-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-24 09:55:54 Starting - Starting the training job...\n",
      "2021-02-24 09:56:17 Starting - Launching requested ML instancesProfilerReport-1614160554: InProgress\n",
      ".........\n",
      "2021-02-24 09:57:38 Starting - Preparing the instances for training......\n",
      "2021-02-24 09:58:44 Downloading - Downloading input data...\n",
      "2021-02-24 09:59:20 Training - Downloading the training image...\n",
      "2021-02-24 09:59:52 Uploading - Uploading generated training model\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 35165 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 8792 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.14867#011validation-error:0.14593\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.14867#011validation-error:0.14593\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.14876#011validation-error:0.14775\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.14631#011validation-error:0.14422\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.14660#011validation-error:0.14468\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.14594#011validation-error:0.14377\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.14273#011validation-error:0.14092\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.14213#011validation-error:0.14036\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.14105#011validation-error:0.13990\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.13966#011validation-error:0.13865\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.13946#011validation-error:0.13899\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.13906#011validation-error:0.13808\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.13727#011validation-error:0.13706\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.13681#011validation-error:0.13683\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.13695#011validation-error:0.13626\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.13670#011validation-error:0.13546\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.13644#011validation-error:0.13444\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.13616#011validation-error:0.13489\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.13584#011validation-error:0.13626\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.13570#011validation-error:0.13535\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.13491#011validation-error:0.13558\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.13408#011validation-error:0.13455\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.13417#011validation-error:0.13421\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.13346#011validation-error:0.13467\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.13323#011validation-error:0.13444\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.13260#011validation-error:0.13319\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.13226#011validation-error:0.13319\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.13212#011validation-error:0.13353\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.13167#011validation-error:0.13319\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.13098#011validation-error:0.13296\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.13090#011validation-error:0.13285\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.12993#011validation-error:0.13239\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.13007#011validation-error:0.13296\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.12962#011validation-error:0.13285\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.12865#011validation-error:0.13296\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.12840#011validation-error:0.13296\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.12814#011validation-error:0.13205\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.12746#011validation-error:0.13160\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.12751#011validation-error:0.13251\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.12717#011validation-error:0.13171\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.12672#011validation-error:0.13126\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.12649#011validation-error:0.13046\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.12638#011validation-error:0.12989\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.12640#011validation-error:0.12955\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.12561#011validation-error:0.12887\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.12521#011validation-error:0.12853\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.12515#011validation-error:0.12830\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.12450#011validation-error:0.12796\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.12421#011validation-error:0.12909\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.12438#011validation-error:0.12818\u001b[0m\n",
      "\n",
      "2021-02-24 10:00:20 Completed - Training job completed\n",
      "ProfilerReport-1614160554: NoIssuesFound\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "container = sagemaker.image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-1')\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    get_execution_role(), \n",
    "                                    hyperparameters=hyperparameters,                                    \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "perceived-newark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-179065836194/sagemaker/blog/output/sagemaker-xgboost-2021-02-24-09-55-54-116/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the model to be used during inference\n",
    "!aws s3 cp s3://sagemaker-us-west-2-179065836194/sagemaker/blog/output/sagemaker-xgboost-2021-02-24-09-55-54-116/output/model.tar.gz model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
